# **Big Data Analysis Using PySpark**



In this project, PySpark was used to analyze a large-scale sales dataset containing 1,000,000 records. Apache Spark enables distributed data processing, making it highly suitable for handling large datasets efficiently and quickly.



The dataset was first generated programmatically and then loaded into a Spark DataFrame. The schema was inferred automatically, confirming attributes such as order ID, product, price, quantity, and country. Various DataFrame operations including aggregation, grouping, and statistical analysis were performed to extract meaningful information from the data.



## **Insights Derived from Big Data Processing**



&nbsp;PySpark successfully processed a dataset containing 1,000,000 records.

&nbsp;Laptop and Mobile products generated higher total sales.

&nbsp;Laptop was identified as the most frequently ordered product.

&nbsp;Average order value varied across countries.

&nbsp;Apache Spark demonstrated scalability and efficiency in handling large datasets.



